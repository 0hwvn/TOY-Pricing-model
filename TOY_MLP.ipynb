{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7edf848b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T12:42:45.684493Z",
     "start_time": "2022-07-20T12:42:44.822328Z"
    }
   },
   "outputs": [],
   "source": [
    "# check for requirements.txt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms # callable\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from torchUtils import * \n",
    "# from models import *\n",
    "# from dataloader import * \n",
    "# Users created package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b346ff7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T12:42:46.171110Z",
     "start_time": "2022-07-20T12:42:46.166603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check if GPu is available\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331fff19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T12:42:46.425094Z",
     "start_time": "2022-07-20T12:42:46.399090Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing & Dataset definition\n",
    "data_root = os.path.join(os.getcwd(),\"data\")\n",
    "# Composes several transforms together.\n",
    "transform = transforms.Compose( \n",
    "    [\n",
    "    transforms.ToTensor(), # PIL Image or ndarray-> FloatTensor with (c,h,w), Intensity to [0,1]\n",
    "    transforms.Normalize([0.5],[0.5]) # normalize each channel of the input\n",
    "    # mean (sequence) – Sequence of means for each channel.\n",
    "    # std (sequence) – Sequence of standard deviations for each channel.\n",
    "    ]\n",
    ")\n",
    "fashion_mnist_dataset = FashionMNIST(data_root, download=True, train=True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd885ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T12:42:47.052264Z",
     "start_time": "2022-07-20T12:42:47.038271Z"
    }
   },
   "outputs": [],
   "source": [
    "data = random_split(fashion_mnist_dataset, [int(len(fashion_mnist_dataset)*0.9),int(len(fashion_mnist_dataset)*0.1)])\n",
    "train_dataset = data[0]\n",
    "val_dataset = data[1]\n",
    "\n",
    "train_batchszie = 100\n",
    "val_batchszie = 10\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=train_batchszie, shuffle =True, num_workers=1\n",
    ")\n",
    "# Iterable object composed of iterable data\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=val_batchszie, shuffle =True, num_workers=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "029f1c4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T12:42:48.657419Z",
     "start_time": "2022-07-20T12:42:47.550404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for sample_batch in train_dataloader:\n",
    "    print(sample_batch[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a859c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T12:42:48.672430Z",
     "start_time": "2022-07-20T12:42:48.658419Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, h1_dim: int, h2_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim,h1_dim)\n",
    "        self.linear2 = nn.Linear(h1_dim,h2_dim)\n",
    "        self.linear3 = nn.Linear(h2_dim,output_dim)\n",
    "        self.relu = F.relu\n",
    "        \n",
    "    def forward(self,input):\n",
    "        x = torch.flatten(input,start_dim=1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        output = self.linear3(x)\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4707f2fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T12:42:48.999344Z",
     "start_time": "2022-07-20T12:42:48.990317Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MLP(28*28,128,64,10)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "max_epoch=15\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c66571",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-20T12:42:50.537Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|███████████████████████████████████████████████████████████████████| 600/600 [00:01<00:00, 301.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: epoch, 0 step: val_loss : 0.2319396436214447, val_acc: 0.03933339938521385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation:   2%|█▎                                                                   | 10/540 [00:01<00:43, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: train_loss : 0.023045382499694823, train_acc: 0.019999999552965164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation:  21%|██████████████▌                                                     | 116/540 [00:02<00:05, 77.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: train_loss : 0.005575298666954041, train_acc: 0.800000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation:  39%|██████████████████████████▊                                         | 213/540 [00:03<00:04, 78.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200: train_loss : 0.00479868620634079, train_acc: 0.8299999833106995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation:  58%|███████████████████████████████████████▏                            | 311/540 [00:04<00:02, 78.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300: train_loss : 0.004638959169387818, train_acc: 0.8399999737739563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation:  77%|████████████████████████████████████████████████████▎               | 415/540 [00:06<00:01, 78.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400: train_loss : 0.004554138481616974, train_acc: 0.8399999737739563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation:  95%|████████████████████████████████████████████████████████████████▌   | 513/540 [00:07<00:00, 78.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500: train_loss : 0.0035730403661727904, train_acc: 0.8799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|████████████████████████████████████████████████████████████████████| 540/540 [00:07<00:00, 67.81it/s]\n",
      "validation: 100%|███████████████████████████████████████████████████████████████████| 600/600 [00:02<00:00, 299.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: epoch, 540 step: val_loss : 0.042681146413087845, val_acc: 0.8456647992134094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation:  14%|█████████▎                                                           | 73/540 [00:01<00:06, 69.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600: train_loss : 0.0048785129189491275, train_acc: 0.8399999737739563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation:  33%|██████████████████████▎                                             | 177/540 [00:03<00:04, 78.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700: train_loss : 0.004529626965522766, train_acc: 0.8299999833106995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation:  51%|██████████████████████████████████▊                                 | 276/540 [00:04<00:03, 79.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800: train_loss : 0.003504478931427002, train_acc: 0.8600000143051147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation:  69%|██████████████████████████████████████████████▊                     | 372/540 [00:05<00:02, 77.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900: train_loss : 0.004266084432601929, train_acc: 0.8199999928474426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation:  87%|██████████████████████████████████████████████████████████▉         | 468/540 [00:06<00:00, 78.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000: train_loss : 0.0033033570647239686, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|████████████████████████████████████████████████████████████████████| 540/540 [00:07<00:00, 67.77it/s]\n",
      "validation:  54%|███████████████████████████████████▊                               | 321/600 [00:01<00:00, 406.63it/s]"
     ]
    }
   ],
   "source": [
    "train_step = 0\n",
    "for epoch in range(1,max_epoch+1):\n",
    "    \n",
    "    # valid step\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        \n",
    "        for val_batch_idx, (val_images,val_labels) in enumerate(tqdm(val_dataloader,position=0,leave=True,desc='validation')):\n",
    "            val_outputs = model(val_images)\n",
    "            _, val_preds = torch.max(val_outputs,1)\n",
    "            val_loss += loss_function(val_outputs,val_labels) / val_outputs.shape[0] # per batch\n",
    "            val_corrects += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0] # per batch\n",
    "    \n",
    "    # Validation logging\n",
    "    val_epoch_loss = val_loss / len(val_dataloader)\n",
    "    val_epoch_acc = val_corrects / len(val_dataloader)\n",
    "    \n",
    "    print(\n",
    "        f\"{epoch}: epoch, {train_step} step: val_loss : {val_epoch_loss}, val_acc: {val_epoch_acc}\"\n",
    "    )\n",
    "    \n",
    "    # train step\n",
    "    for batch_idx, (images,labels) in enumerate(tqdm(train_dataloader,position=0,leave=True,desc='validation')):\n",
    "        current_loss = 0.0\n",
    "        current_corrects = 0\n",
    "        \n",
    "        #Forward\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs,1)\n",
    "        loss = loss_function(outputs,labels)\n",
    "        \n",
    "        #Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        current_loss += loss.item()\n",
    "        current_corrects += torch.sum(preds==labels.data)\n",
    "        # Train logging\n",
    "        if train_step % log_interval == 0: # Performance log per batch\n",
    "            train_loss = current_loss / log_interval # average loss\n",
    "            train_acc = current_corrects / log_interval # average acc\n",
    "            print(\n",
    "                f\"{train_step}: train_loss : {train_loss}, train_acc: {train_acc}\"\n",
    "            )\n",
    "            current_loss = 0\n",
    "            current_corrects = 0\n",
    "            \n",
    "        train_step+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26178923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SKT-env",
   "language": "python",
   "name": "skt-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
